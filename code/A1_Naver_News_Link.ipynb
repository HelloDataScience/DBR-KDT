{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4411ba6e",
   "metadata": {},
   "source": [
    "## 네이버 뉴스 링크 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9981d77-c98a-471d-b99f-68a01e26a4f9",
   "metadata": {},
   "source": [
    "### 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 라이브러리를 호출합니다.\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup as BTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa711761-2e29-4aa3-9e7a-b388dab9e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일간지 기사에서 네이버뉴스 링크를 수집하고 데이터프레임으로 반환하는 함수를 생성합니다.\n",
    "def NaverNewsLink(searchWord, period = None, bgnDate = None, endDate = None, startNo = 1):\n",
    "\n",
    "    # 조회 구분을 설정합니다.\n",
    "    if period is not None:\n",
    "        period = 3  # 0: 전체, 4: 1일, 1: 1주, 2: 1개월, 13: 3개월, 6: 6개월, 5: 1년, 3: 직접입력\n",
    "    else:\n",
    "        period = 0\n",
    "        \n",
    "    # HTTP 요청을 실행합니다.\n",
    "    res = requests.get(\n",
    "        url = 'https://s.search.naver.com/p/newssearch/2/search.naver', \n",
    "        params = {\n",
    "            'office_category': 1,  # 0: 전체, 1: 일간지, 2: 방송/통신, 3: 경제/IT, 4: 인터넷신문, 5: 스포츠/연예, 6: 지역지, 7: 매거진, 8: 전문지/기타\n",
    "            'office_type': 3,  # 0: 전체, 1: 지역언론사별, 2: 가나다순, 3: 언론사 분류순\n",
    "            'pd': period,\n",
    "            'ds': bgnDate, \n",
    "            'de': endDate, \n",
    "            'query': searchWord,\n",
    "            'rev': 31,\n",
    "            'service_area': 0,  # 0: 전체, 1: 모바일 메인 언론사, 2: PC 메인 언론사\n",
    "            'sort': 1,  # 0: 관련도순, 1: 최신순, 2: 오래된순\n",
    "            'spq': 3, \n",
    "            'start': startNo,\n",
    "            'where': 'news_tab_api',\n",
    "            'nso': 'so:r,p:all,a:all'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # JSON 형태의 문자열을 딕셔너리로 변환합니다.\n",
    "    dat = json.loads(s = res.text)\n",
    "\n",
    "    # 딕셔너리에서 HTML 형태의 문자열을 bs4.BeautifulSoup 객체로 변환합니다.\n",
    "    soup = BTS(markup = dat['collection'][0]['html'], features = 'html.parser')\n",
    "\n",
    "    # 네이버뉴스 링크를 포함하는 HTML 요소를 선택합니다.\n",
    "    items = soup.select('div.info_group > a.info:nth-child(3)')\n",
    "\n",
    "    # 네이버뉴스 링크를 시리즈로 생성합니다.\n",
    "    links = pd.Series(data = [item['href'] for item in items])\n",
    "\n",
    "    # 시리즈를 반환합니다.\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수를 테스트합니다.\n",
    "links = NaverNewsLink(searchWord = '백종원')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa57339-62d8-4546-98ab-7b839bee4528",
   "metadata": {},
   "source": [
    "### 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8401d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최종 결과를 저장할 빈 시리즈를 생성합니다.\n",
    "newsLinks = pd.Series(dtype = str)\n",
    "\n",
    "# 반복문 시작 위치를 설정합니다.\n",
    "i = 1\n",
    "\n",
    "# while 반복문으로 관련 네이버뉴스 링크를 수집합니다.(최대 1000개까지)\n",
    "# [참고] 일간지 기사에서 네이버뉴스 링크가 없는 경우가 많습니다.\n",
    "while i <= 1000:\n",
    "\n",
    "    # 시작 위치를 출력합니다.\n",
    "    print(i)\n",
    "\n",
    "    # 네이버뉴스 링크를 수집하고 links에 할당합니다.\n",
    "    links = NaverNewsLink(\n",
    "        searchWord = '백종원', \n",
    "        period = 3, \n",
    "        bgnDate = '2025.01.01', \n",
    "        endDate = '2025.04.14', \n",
    "        startNo = i\n",
    "    )\n",
    "\n",
    "    # 새로 수집한 네이버뉴스 링크 개수를 n에 할당합니다. \n",
    "    n = len(links)\n",
    "\n",
    "    # 새로 수집한 네이버뉴스 링크 개수가 0이면 반복문을 중단합니다.\n",
    "    # 새로 수집한 네이버뉴스 링크와 직전에 수집한 네이버뉴스 링크가 일치하면 반복문을 중단합니다.\n",
    "    # 두 시리즈가 일치하지 않으면 최종 결과에 새로 수집한 네이버뉴스 링크에 추가합니다.\n",
    "    if n == 0:\n",
    "        break\n",
    "    elif links.equals(newsLinks.iloc[-n:]): \n",
    "        break\n",
    "    else:\n",
    "        newsLinks = pd.concat(objs = [newsLinks, links], ignore_index = True)\n",
    "\n",
    "    # 시작 위치를 업데이트합니다.\n",
    "    i += 10\n",
    "    \n",
    "    # 1초간 멈춥니다.\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks의 처음 5행을 확인합니다.\n",
    "newsLinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779430fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks의 정보를 확인합니다.\n",
    "newsLinks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b6ea0-7c53-4e0c-a3a4-1e7693d3e3bc",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f67dd-7bcc-49e2-9f03-8cd90023f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks에서 쿼리 문자열 패턴이 있는지 확인합니다.\n",
    "newsLinks.str.contains(pat = '(\\?.+)').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91007fcc-e1ca-4fcb-a7cb-56d12b381d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks에서 쿼리 문자열 패턴을 추출하고 도수를 확인합니다.\n",
    "newsLinks.str.extractall(pat = '(\\?.+)')[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46971cd-6477-44f3-8e9a-1277e476f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks에서 쿼리 문자열을 삭제하고 newsLinks에 재할당합니다.\n",
    "newsLinks = newsLinks.str.replace(pat = '(\\?.+)', repl = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks에서 원소의 중복 여부를 dups로 생성합니다.\n",
    "# [참고] keep 매개변수에 'first'를 지정하면 첫 번째 중복 건은 False로 반환합니다.\n",
    "dups = newsLinks.duplicated(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks에서 중복인 행을 삭제하고 newsLinks에 재할당합니다.\n",
    "if dups.sum() > 0:\n",
    "    newsLinks = newsLinks.loc[~dups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks의 행 개수를 확인합니다.\n",
    "newsLinks.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797f281-286a-4e15-a8bb-3fc2bec65957",
   "metadata": {},
   "source": [
    "### 외부 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 작업 경로를 확인합니다.\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d737bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 폴더로 작업 경로를 변경합니다.\n",
    "os.chdir(path = '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsLinks를 pkl 파일로 저장합니다.\n",
    "pd.to_pickle(obj = newsLinks, filepath_or_buffer = 'Naver_News_Link.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 작업 경로에 있는 폴더명과 파일명을 확인합니다.\n",
    "sorted(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b550c3b3",
   "metadata": {},
   "source": [
    "## End of Document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
