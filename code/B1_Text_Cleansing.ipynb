{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a6dfd1-5496-42d6-bd6b-d1f1020812d4",
   "metadata": {},
   "source": [
    "## 텍스트 정제: 오탈자 및 띄어쓰기 교정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0dda6-800b-4329-a87e-de00b15e4fbe",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c4876-b8de-4940-ba7e-1346aaba3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 라이브러리를 호출합니다.\n",
    "import os\n",
    "import shutil\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbeb82b-0482-440e-9a62-ab24e7b92052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 구어체 맞춤법 교정을 위한 언어 모델명을 설정합니다.\n",
    "model_name = 'j5ng/et5-typos-corrector'\n",
    "\n",
    "# 문서 폴더에 모델을 저장할 폴더를 생성합니다.\n",
    "download_dir = os.path.join(os.path.expanduser(path = '~'), 'Downloads')\n",
    "model_dir = os.path.join('HuggingFace', model_name.replace('/', '-'))\n",
    "local_model_dir = os.path.join(download_dir, model_dir)\n",
    "\n",
    "# 모델을 저장하거나 저장된 모델을 불러와서 초기화합니다.\n",
    "if not os.path.exists(path = local_model_dir):\n",
    "    print('모델을 다운로드합니다...')\n",
    "    \n",
    "    # T5 기반 언어 모델과 토크나이저를 초기화합니다.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\n",
    "        pretrained_model_name_or_path = model_name, \n",
    "        cache_dir = local_model_dir\n",
    "    )\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path = model_name, \n",
    "        cache_dir = local_model_dir\n",
    "    )\n",
    "    \n",
    "    # 모델을 로컬 폴더에 저장합니다.\n",
    "    model.save_pretrained(save_directory = local_model_dir)\n",
    "    tokenizer.save_pretrained(save_directory = local_model_dir)\n",
    "    print(f'모델을 \"{local_model_dir}\"에 저장했습니다.')\n",
    "    \n",
    "    # 모델을 임시로 저장했던 폴더를 삭제합니다.\n",
    "    delete_folder = os.path.join(local_model_dir, f'models--{model_name.replace(\"/\", \"--\")}')\n",
    "    if os.path.exists(path = delete_folder):\n",
    "        shutil.rmtree(path = delete_folder)\n",
    "    \n",
    "else:\n",
    "    print('저장된 모델을 불러옵니다...')\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\n",
    "        pretrained_model_name_or_path = local_model_dir\n",
    "    )\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path = local_model_dir\n",
    "    )\n",
    "\n",
    "print('모델 로딩을 완료했습니다!')\n",
    "\n",
    "# 사용 가능한 디바이스를 확인합니다.\n",
    "# [참고] MacOS M1에서 실행할 때 'cuda:0'을 'mps:0'으로 대신합니다.\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 모델을 사용 가능한 디바이스로 이동시킵니다.\n",
    "model = model.to(device)\n",
    "\n",
    "# 한글 구어체 맞춤법 검사기를 생성합니다.\n",
    "def et5_typo_corrector(text, seed = 1):\n",
    "    \n",
    "    # 프롬프트를 설정합니다.\n",
    "    prompt = '원본 내용을 보존하면서 맞춤법을 고쳐주세요: '\n",
    "\n",
    "    # 입력 텍스트를 모델에 입력할 PyTorch 텐서 형식으로 인코딩합니다.\n",
    "    input_encoding = tokenizer(\n",
    "        text = prompt + text,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    # 모델의 generate 함수를 사용하여 텍스트를 생성합니다.\n",
    "    # input_ids와 attention_mask를 선택한 디바이스(cpu 또는 gpu)로 옮깁니다.\n",
    "    # max_length: 출력 텍스트의 최대 토큰 수를 설정합니다.\n",
    "    # num_beams: Beam Search 기법에서 사용할 빔의 개수를 지정합니다.\n",
    "    # [참고] Beam Search는 여러 후보 문장에서 가장 확률 높은 문장을 선택합니다.\n",
    "    # early_stopping: 최적 문장이 확정되면 조기에 탐색을 종료합니다.\n",
    "    # length_penalty: 출력 텍스트의 길이를 줄이거나 늘리지 않도록 설정합니다.\n",
    "    # [참고] 0.8은 짧은 문장 선호, 1.0은 기본값, 1.2는 긴 문장을 선호합니다.\n",
    "    # do_sample: False는 확률적 샘플링, True는 결정적 탐색을 수행합니다.(창의적 문장 방지)\n",
    "    # no_repeat_ngram_size: 같은 n-gram을 반복하지 않도록 설정합니다.\n",
    "    # repetition_penalty: 반복할 때 페널티를 부여하도록 설정합니다.(보통 1.0보다 큰 값 사용)\n",
    "    # top_k, top_p: 완전한 무작위 샘플링 대신 상위 k개의 후보 또는 누적 확률 p 범위 내에서 \n",
    "    # 샘플링하는 방법을 사용하면 다양성을 유지하면서 결과의 품질과 일관성을 높일 수 있습니다.\n",
    "    # [참고] do_sample = True일 때 top_k와 top_p 매개변수는 적용되지 않습니다.\n",
    "    with torch.no_grad():\n",
    "        output_encoding = model.generate(\n",
    "            input_ids = input_encoding.input_ids.to(device),\n",
    "            attention_mask = input_encoding.attention_mask.to(device),\n",
    "            max_length = len(text) + 20,\n",
    "            num_beams = 5,\n",
    "            early_stopping = False,\n",
    "            length_penalty = 1.5,\n",
    "            do_sample = False, \n",
    "            no_repeat_ngram_size = 3,\n",
    "            repetition_penalty = 1.5,\n",
    "            # top_k = 50,\n",
    "            # top_p = 0.95\n",
    "        )\n",
    "\n",
    "    # 모델이 생성한 토큰 시퀀스를 사람이 읽을 수 있는 텍스트로 변환합니다.\n",
    "    # skip_special_tokens = True 옵션은 [PAD], [EOS] 등의 특수 토큰을 제거합니다.\n",
    "    output_text = tokenizer.decode(\n",
    "        token_ids = output_encoding[0],\n",
    "        skip_special_tokens = True\n",
    "    )\n",
    "\n",
    "    # 결과 텍스트를 반환합니다.\n",
    "    return output_text\n",
    "\n",
    "# 한글 맞춤법 검사기를 실행하는 재귀함수를 생성합니다.\n",
    "def correct(text, show_process = True):\n",
    "    \n",
    "    # 입력 문장의 클래스에 맞게 한글 맞춤법 검사를 실행합니다.\n",
    "    if isinstance(text, str):\n",
    "        return et5_typo_corrector(text = text)\n",
    "    \n",
    "    elif isinstance(text, pd.Series):\n",
    "        iterator = tqdm(text) if show_process else text\n",
    "        return type(text)((correct(text = item, show_process = False) for item in iterator), index = text.index)\n",
    "    \n",
    "    elif isinstance(text, (list, tuple, np.ndarray)):\n",
    "        iterator = tqdm(text) if show_process else text\n",
    "        return type(text)(correct(text = item, show_process = False) for item in iterator)\n",
    "    \n",
    "    else:\n",
    "        raise TypeError('문자열, 리스트, 튜플, 또는 시리즈를 입력하세요!')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e8403-761a-4688-a0f6-409bde6237b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 작업 경로를 확인합니다.\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb6595-663e-4cfa-9b23-167d4afceaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 폴더로 작업 경로를 변경합니다.\n",
    "os.chdir(path = '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41c37e-a69f-4014-8fd7-71eaf13f7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 작업 경로에 있는 폴더명과 파일명을 확인합니다.\n",
    "sorted(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4edb7-2992-4d91-9b5e-2023e8cadcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl 파일을 읽고 newsReply를 생성합니다.\n",
    "newsReply = pd.read_pickle(filepath_or_buffer = 'Naver_News_Reply.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bc4e3-bfc2-42d4-98d7-643066b0f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply의 처음 5행을 확인합니다.\n",
    "newsReply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101dcda-934d-49ed-b3ec-947438d00d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply의 정보를 확인합니다.\n",
    "newsReply.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145f73c-ae75-4735-9862-d105e989be96",
   "metadata": {},
   "source": [
    "### 불필요한 문자/기호 제거 및 알파벳 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fdf4d4-5304-4b6b-a0a7-c3cb4a7efccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규 표현식 패턴을 설정합니다.\n",
    "pt = '[^가-힣A-Za-z0-9]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be820758-2507-4820-ab9f-e57beece97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply에서 정규 표현식 패턴을 한 칸 공백으로 변경합니다.\n",
    "newsReply['contents'] = newsReply['contents'].str.replace(pat = pt, repl = ' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c02061-8158-4b7f-ac70-c1a9ee378548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply에서 모든 알파벳을 대문자로 변경합니다.\n",
    "newsReply['contents'] = newsReply['contents'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e557c-663c-42f5-9b9a-97340d8b50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply의 처음 5행을 확인합니다.\n",
    "newsReply['contents'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e536ce0-085f-40fa-b540-fb75c0c0f527",
   "metadata": {},
   "source": [
    "### 한글 맞춤법 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e605cc-0ea7-4f0f-b4a1-dd4f9fe98019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 텍스트로 한글 맞춤법 검사를 수행합니다.\n",
    "correct(text = '복리후생으로워라벨부터챙기자')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c0f9f-b9f1-4d6c-b5be-adfe91ffcfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 텍스트로 한글 맞춤법 검사를 수행합니다.\n",
    "# [참고] text 매개변수에 문자열을 원소로 갖는 리스트, 배열, 시리즈를 지정할 수 있습니다.\n",
    "correct(text = ['지인짜 감사하빈다', '빠른 배송조아여', '증말 마씨게따'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d2fe5-eacc-4af5-865a-626b0950d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 집합으로 한글 맞춤법 검사를 수행하고 corrected를 생성합니다.\n",
    "newsReply['corrected'] = correct(text = newsReply['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54a204-a0d5-454b-9699-af21a594ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply에서 contents와 corrected를 선택하고 처음 10행을 확인합니다.\n",
    "newsReply[['contents', 'corrected']].head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eddd76-dc54-4757-a42c-dc3f76c681da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply에서 contents와 corrected를 선택하고 마지막 10행을 확인합니다.\n",
    "newsReply[['contents', 'corrected']].tail(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53370e40-495d-40c3-ab02-d11bca95fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본에 없는 프롬프트를 수작업으로 삭제합니다.\n",
    "newsReply['corrected'] = newsReply['corrected'].str.replace(pat = '원본 내용을 보존하면서.', repl = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc843cd8-74d0-4146-94e9-79d834f3ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply에서 contents와 corrected를 선택하고 마지막 10행을 확인합니다.\n",
    "newsReply[['contents', 'corrected']].tail(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabad80b-8929-481a-97a9-c7eaf0f39810",
   "metadata": {},
   "source": [
    "### 외부 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bed0b-2b39-4eed-a9c0-e9b8739e82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsReply를 pkl 파일로 저장합니다.\n",
    "pd.to_pickle(obj = newsReply, filepath_or_buffer = 'Naver_News_Reply.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7dbe95-d7b1-4caa-ab19-50b7cca86b9a",
   "metadata": {},
   "source": [
    "## End of Document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
